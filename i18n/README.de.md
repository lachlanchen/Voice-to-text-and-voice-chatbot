[English](../README.md) Â· [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README.ar.md) Â· [EspaÃ±ol](README.es.md) Â· [FranÃ§ais](README.fr.md) Â· [æ—¥æœ¬èª](README.ja.md) Â· [í•œêµ­ì–´](README.ko.md) Â· [Tiáº¿ng Viá»‡t](README.vi.md) Â· [ä¸­æ–‡ (ç®€ä½“)](README.zh-Hans.md) Â· [ä¸­æ–‡ï¼ˆç¹é«”ï¼‰](README.zh-Hant.md) Â· [Deutsch](README.de.md) Â· [Ğ ÑƒÑÑĞºĞ¸Ğ¹](README.ru.md)


[![LazyingArt banner](https://github.com/lachlanchen/lachlanchen/raw/main/figs/banner.png)](https://github.com/lachlanchen/lachlanchen/blob/main/figs/banner.png)

# Voice-to-Voice Chatbot mit Whisper, LLaMA und Groq API

![Python](https://img.shields.io/badge/Python-3.7%2B-3776AB?logo=python&logoColor=white)
![Whisper](https://img.shields.io/badge/STT-OpenAI%20Whisper-1f6feb)
![Groq](https://img.shields.io/badge/LLM-Groq%20LLaMA%203--8B-FF6B35)
![gTTS](https://img.shields.io/badge/TTS-Google%20Text-to-Speech-34A853)
![UI](https://img.shields.io/badge/UI-Gradio-F97316)
![Status](https://img.shields.io/badge/Project-Active%20Prototype-2ea44f)
![Platform](https://img.shields.io/badge/Runtime-Local%20%2F%20Colab-0EA5E9?logo=jupyter&logoColor=white)

Dieses Repository stellt einen kompakten Voice-to-Voice-Chatbot in einer einzelnen Datei bereit. Es nimmt Sprache auf, transkribiert sie mit Whisper, sendet den Text an Groq-gehostetes LLaMA fÃ¼r die Verarbeitung und erzeugt eine gesprochene Antwort mit Google Text-to-Speech (gTTS). Die Nutzerinteraktion lÃ¤uft Ã¼ber Gradio mit Text- und Audioausgaben.

> **Ziel:** Eine praktische, reproduzierbare Pipeline, die du lokal oder in Colab mit einem einzelnen Hauptskript ausfÃ¼hren kannst.

## ğŸ§­ SchnellÃ¼bersicht

| Bereich | Status |
|---|---|
| Sprachumfang | `README.md` plus mehrsprachige Kopien in `i18n/` |
| Single Source of Truth | Englisches Root-README steuert den Lokalisierungsabgleich |
| Empfohlener AusfÃ¼hrungsmodus | `Local` zuerst, `Colab` danach |

## ğŸ” Details zur SchnellÃ¼bersicht

| Fokus | Status |
|---|---|
| Einstiegspunkt | `voice_to_voice_chatbot.py` |
| OberflÃ¤che | Gradio-basierte Web-UI mit Text + Audio |
| STT-Modell | Whisper (`base`) |
| LLM-Backend | Groq-gehostetes `llama3-8b-8192` |
| TTS-Engine | Google Text-to-Speech |
| Sprachdokumentation | 10+ Ã¼bersetzte README-Dateien in `i18n/` |

## Ãœberblick

Die App implementiert eine vollstÃ¤ndige Konversationspipeline in `voice_to_voice_chatbot.py`:

1. Nutzer*innen-Audio wird Ã¼ber Mikrofon oder Datei-Upload empfangen.
2. Sprache wird mit dem Whisper (`base`)-Modell transkribiert.
3. Groq + `llama3-8b-8192` erzeugen eine Antwort.
4. Der Text wird mit gTTS in eine MP3-Datei umgewandelt.
5. Die Textantwort und Wiedergabesteuerung werden in Gradio dargestellt.

### Konversations-Pipeline

| Stufe | Komponente | Ausgabe |
|---|---|---|
| ğŸ™ï¸ Eingabe | `gr.Audio(type="filepath")` | Audio-Dateipfad |
| ğŸ“ Transkription | Whisper `base`-Modell | Transkript-Text |
| ğŸ§  Verarbeitung | Groq Chat Completion | Assistententext |
| ğŸ”Š Synthese | `gTTS` | MP3-Antwort-Pfad |
| ğŸ–¥ï¸ Bereitstellung | Gradio `Interface` | Antworttext + Audio-Wiedergabe |

```mermaid
flowchart LR
    A[Audioeingabe] --> B[Whisper-Transkription]
    B --> C[Groq LLaMA-Verarbeitung]
    C --> D[gTTS-Synthese]
    D --> E[Gradio-Ausgabe: Text + MP3]
```

## â­ Features

- **STT + LLM + TTS in einem Skript**: voller Sprach-Loop in `voice_to_voice_chatbot.py`.
- **Mikrofon- und DateiunterstÃ¼tzung**: Direkte Spracheingabe oder Upload bereits aufgezeichneter Dateien.
- **Leichtgewichtiges Setup**: nur ein kleiner Satz an Python-Paketen.
- **Mehrsprachige Dokumentation**: Lokalisierte READMEs werden in `i18n/` gepflegt.
- **Praktische Fehlersichtbarkeit**: Fehlertexte auf Funktionsniveau erscheinen in der UI und beschleunigen die Iteration.

## ğŸ“ Projektstruktur

```text
Voice-to-text-and-voice-chatbot/
    â”œâ”€â”€ requirements.txt              # Python-AbhÃ¤ngigkeiten
    â”œâ”€â”€ voice_to_voice_chatbot.py     # Hauptanwendungsskript
    â”œâ”€â”€ i18n/                        # Ãœbersetzte README-Dateien
â”‚   â”œâ”€â”€ README.ar.md
â”‚   â”œâ”€â”€ README.de.md
â”‚   â”œâ”€â”€ README.es.md
â”‚   â”œâ”€â”€ README.fr.md
â”‚   â”œâ”€â”€ README.ja.md
â”‚   â”œâ”€â”€ README.ko.md
â”‚   â”œâ”€â”€ README.ru.md
â”‚   â”œâ”€â”€ README.vi.md
â”‚   â”œâ”€â”€ README.zh-Hans.md
â”‚   â””â”€â”€ README.zh-Hant.md
â””â”€â”€ .auto-readme-work/            # Metadaten fÃ¼r die README-Generierung
    â”œâ”€â”€ 20260228_230442/
    â”œâ”€â”€ 20260301_064403/
    â””â”€â”€ 20260301_065134/
        â”œâ”€â”€ language-nav-i18n.md
        â”œâ”€â”€ language-nav-root.md
        â”œâ”€â”€ pipeline-context.md
        â””â”€â”€ translation-plan.txt
```

## ğŸŒ Lokalisierung und Dokumentation

Dieses README-Projekt hÃ¤lt ein einziges Quell-README in Englisch als Referenz und stellt Ãœbersetzungen in `i18n/` bereit.

- Nutze die Sprachlinks im oberen Bereich dieser Datei, um zwischen den README-Versionen zu wechseln.
- Bestehende Ãœbersetzungen decken Ã¼ber 10 Sprachen ab und sollten in Struktur und Inhalt mit dem englischen Original synchron bleiben.
- Bevorzuge eine Aktualisierung des englischen READMEs zuerst, anschlieÃŸend die Ãœbersetzungen strukturell angleichen.

## âœ… Voraussetzungen

- Python 3.7+ Runtime.
- Ein gÃ¼ltiger Groq API-SchlÃ¼ssel.
- Internetzugang fÃ¼r den Download des Whisper-Modells und API-Aufrufe.
- Optional: Mikrofonberechtigung im Browser bei Nutzung der Live-Audio-Funktion.
- Optional: Eine GPU kann Latenz und Konsistenz der Whisper-Transkription verbessern.

### Anforderungen auf einen Blick

| Anforderung | Warum sie nÃ¶tig ist |
|---|---|
| Python `3.7+` | Laufzeit fÃ¼r Gradio, Whisper und weitere AbhÃ¤ngigkeiten |
| Groq API-Key | BenÃ¶tigt fÃ¼r Aufrufe der LLM-Inferenz |
| `requirements.txt` | Installiert alle benÃ¶tigten Python-Pakete |
| Browser-Mikrofonzugriff | ErmÃ¶glicht Spracheingabe Ã¼ber Gradio |

## ğŸ› ï¸ Installation

1. Repository klonen:

```bash
git clone <repo-url>
cd Voice-to-text-and-voice-chatbot
```

2. AbhÃ¤ngigkeiten installieren:

```bash
pip install -r requirements.txt
```

FÃ¼r Google Colab verwende:

```python
!pip install -U gradio openai-whisper gtts groq
```

### Hinweise

- Das Repository enthÃ¤lt aktuell sowohl `whisper` als auch `openai-whisper` in den AbhÃ¤ngigkeiten.
- Bei Paketkonflikten verwende bevorzugt die Variante passend zu deiner Umgebung und entferne redundante Installationen nach Validierung.

## ğŸ§¯ Laufbereitschafts-Checkliste

| Schritt | PrÃ¼fung |
|---|---|
| API-SchlÃ¼ssel | `GROQ_API_KEY` oder vertrauenswÃ¼rdiger lokaler Fallback ist korrekt konfiguriert |
| AudiogerÃ¤t | Browser-Mikrofon ist fÃ¼r Live-Eingabe aktiviert |
| Laufzeitpfad | Befehle laufen aus dem Projekt-Root bei installierten AbhÃ¤ngigkeiten |
| Ausgabepfad | TemporÃ¤re Verzeichnisse sind beschreibbar fÃ¼r MP3-Antworten |

## âš™ï¸ Konfiguration

### Umgebungsvariable (empfohlen)

```bash
export GROQ_API_KEY='your_groq_api_key'
```

In der Colab-Runtime:

```python
import os
os.environ['GROQ_API_KEY'] = 'your_groq_api_key'
```

### Wichtiger Laufzeit-Hinweis (aktuelles Verhalten)

`voice_to_voice_chatbot.py` initialisiert Groq derzeit so:

```python
client = Groq(
    api_key="your_groq_api_key",
)
```

Wenn du nur `GROQ_API_KEY` setzt, aktualisiere das Skript auf `os.getenv` oder hinterlege einen vertrauenswÃ¼rdigen lokalen Umgebungswert hartkodiert vor dem Start:

```python
client = Groq(api_key=os.getenv("GROQ_API_KEY", "your_groq_api_key"))
```

### Annahmen

- Dieses Repository ist fÃ¼r den Betrieb in einer lokalen Python-Umgebung oder Colab gedacht.
- Es ist kein separates Server-Entrypoint oder Bereitstellungs-Setup in diesem Snapshot enthalten.

## â–¶ï¸ Verwendung

Starte die Anwendung mit:

```bash
python voice_to_voice_chatbot.py
```

Gradio startet eine lokale OberflÃ¤che mit einem Audioeingang und zwei Ausgaben:

- `Response Text`
- `Response Audio`

### Interaktion mit dem Chatbot

- **Mikrofon**: Aufzeichnen klicken und sprechen; das Audio wird transkribiert, beantwortet und wiedergegeben.
- **Datei hochladen**: Eine Audiodatei auswÃ¤hlen, die transkribiert und als Basis fÃ¼r die Antwort genutzt wird.

## ğŸ¬ Beispiele

### Beispielablauf

1. Frage: "What are three tips to learn Python quickly?"
2. Whisper liefert ein Transkript.
3. Groq erstellt eine Antwort.
4. gTTS synthetisiert die Ausgabe.
5. UI zeigt Text und Audio-Antwort an.

### Erwartete Ausgabe

- Erfolgreiche Transkription im Antwort-Textfeld.
- Nicht leere gesprochene Antwortdatei im Gradio-Audioplayer.

## ğŸ§ª Entwicklungsnotizen

- Kernfunktion: `chatbot_pipeline(audio_path)`.
- Whisper wird einmalig beim Modulimport mit `whisper.load_model("base")` geladen.
- Audioausgabe nutzt `NamedTemporaryFile(..., delete=False)` fÃ¼r MP3-Persistenz.
- Fehlerpfad gibt `(str(e), None)` zurÃ¼ck, um die UI bei Fehlern responsiv zu halten.
- `iface.launch()` wird beim Modulimport aufgerufen; fÃ¼r nutzbare Bibliotheksintegration sollte Startcode mit `if __name__ == "__main__":` geschÃ¼tzt werden.

## ğŸ Fehlerbehebung

### HÃ¤ufige Probleme

- `ModuleNotFoundError` fÃ¼r Whisper:

```bash
pip install -U openai-whisper
```

- Groq-Authentifizierungsfehler:
  - Stelle sicher, dass der Platzhalter-API-SchlÃ¼ssel ersetzt oder aus den Umgebungsvariablen geladen ist.
  - PrÃ¼fe, ob der SchlÃ¼ssel ausreichende Berechtigungen und Kontingente hat.

- Keine Audioausgabe:
  - PrÃ¼fe ausgehende KonnektivitÃ¤t fÃ¼r Groq und gTTS.
  - Stelle sicher, dass der temporÃ¤re MP3-Pfad in der Umgebung beschreibbar ist.

### Kurze Fehlerdiagnose-Checkliste

| PrÃ¼fung | Validierung |
|---|---|
| API-SchlÃ¼sselquelle | `Groq(api_key=...)` ist ein gÃ¼ltiger SchlÃ¼ssel |
| STT-AbhÃ¤ngigkeit | `import whisper` und `openai-whisper`-Import funktionieren |
| Audio-Pfad | Gradio erhÃ¤lt einen gÃ¼ltigen Audio-Dateipfad |
| Ausgabe-Rendern | UI gibt sowohl Antworttext als auch Audio aus |

## ğŸ—ºï¸ Roadmap

- Harte Codierung des Groq-SchlÃ¼ssels durch standardmÃ¤ÃŸige env-basierte Konfiguration ersetzen.
- Modellauswahl per Umgebung (Whisper-GrÃ¶ÃŸe, Groq-Modell-ID) ergÃ¤nzen.
- Minimale Tests fÃ¼r Hilfsfunktionen hinzufÃ¼gen.
- CLI- und Deployment-Vorlagen ergÃ¤nzen (Docker/Hugging Face Spaces).

## â™»ï¸ Wartungs- und Sync-Strategie

Zur Sicherstellung konsistenter QualitÃ¤t multilinguale READMEs:

1. Aktualisiere zuerst das englische `README.md` bei strukturellen oder technischen Ã„nderungen.
2. Ãœbernehme Ãœberschriften und SchlÃ¼sselinhalte strukturell in die Ãœbersetzungen unter `i18n/`.
3. Halte Banner- und Support-Block in allen lokalen Versionen konsistent.

## ğŸ¤ Mitwirken

BeitrÃ¤ge sind willkommen. Empfohlener Ablauf:

1. Repository forken.
2. Einen Feature-Branch erstellen.
3. Ã„nderungen implementieren.
4. Einen klaren Pull Request mit BegrÃ¼ndung und Testnotizen erÃ¶ffnen.

## ğŸ“„ Lizenz

Dieses Repository verweist auf eine beabsichtigte MIT-Lizenz, aber es ist keine `LICENSE`-Datei in diesem Snapshot vorhanden. Bitte fÃ¼ge eine Lizenzdatei hinzu, falls eine Verteilung unter Lizenz erforderlich ist.


## â¤ï¸ Support

| Donate | PayPal | Stripe |
| --- | --- | --- |
| [![Donate](https://camo.githubusercontent.com/24a4914f0b42c6f435f9e101621f1e52535b02c225764b2f6cc99416926004b7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d4c617a79696e674172742d3045413545393f7374796c653d666f722d7468652d6261646765266c6f676f3d6b6f2d6669266c6f676f436f6c6f723d7768697465)](https://chat.lazying.art/donate) | [![PayPal](https://camo.githubusercontent.com/d0f57e8b016517a4b06961b24d0ca87d62fdba16e18bbdb6aba28e978dc0ea21/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f50617950616c2d526f6e677a686f754368656e2d3030343537433f7374796c653d666f722d7468652d6261646765266c6f676f3d70617970616c266c6f676f436f6c6f723d7768697465)](https://paypal.me/RongzhouChen) | [![Stripe](https://camo.githubusercontent.com/1152dfe04b6943afe3a8d2953676749603fb9f95e24088c92c97a01a897b4942/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5374726970652d446f6e6174652d3633354246463f7374796c653d666f722d7468652d6261646765266c6f676f3d737472697065266c6f676f436f6c6f723d7768697465)](https://buy.stripe.com/aFadR8gIaflgfQV6T4fw400) |
