[English](../README.md) Â· [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README.ar.md) Â· [EspaÃ±ol](README.es.md) Â· [FranÃ§ais](README.fr.md) Â· [æ—¥æœ¬èª](README.ja.md) Â· [í•œêµ­ì–´](README.ko.md) Â· [Tiáº¿ng Viá»‡t](README.vi.md) Â· [ä¸­æ–‡ (ç®€ä½“)](README.zh-Hans.md) Â· [ä¸­æ–‡ï¼ˆç¹é«”ï¼‰](README.zh-Hant.md) Â· [Deutsch](README.de.md) Â· [Ğ ÑƒÑÑĞºĞ¸Ğ¹](README.ru.md)


[![LazyingArt banner](https://github.com/lachlanchen/lachlanchen/raw/main/figs/banner.png)](https://github.com/lachlanchen/lachlanchen/blob/main/figs/banner.png)

# Voice-to-Voice-Chatbot mit Whisper, LLaMA und Groq API

![Python](https://img.shields.io/badge/Python-3.7%2B-3776AB?logo=python&logoColor=white)
![Whisper](https://img.shields.io/badge/STT-OpenAI%20Whisper-1f6feb)
![Groq](https://img.shields.io/badge/LLM-Groq%20LLaMA%203--8B-FF6B35)
![gTTS](https://img.shields.io/badge/TTS-Google%20gTTS-34A853)
![UI](https://img.shields.io/badge/UI-Gradio-F97316)
![Status](https://img.shields.io/badge/Project-Active%20Prototype-2ea44f)

Dieses Projekt ist ein Echtzeit-Voice-to-Voice-Chatbot, der OpenAIs Whisper fÃ¼r die Sprache-zu-Text-Transkription nutzt, Groq API mit LLaMA 3 8B zur Generierung von Antworten verwendet und Google Text-to-Speech (gTTS) fÃ¼r die Umwandlung von Text zurÃ¼ck in Sprache einsetzt. Die OberflÃ¤che basiert auf Gradio, sodass Nutzer:innen per Spracheingabe oder durch Hochladen von Audiodateien interagieren kÃ¶nnen.

## Ãœberblick

Die App implementiert einen vollstÃ¤ndigen Audio-Konversationsablauf in einem einzelnen Python-Skript:

1. Erfasst Audiodaten aus Mikrofon oder hochgeladener Datei.
2. Transkribiert Sprache mit dem Whisper-Modell (`base`) in Text.
3. Generiert eine Antwort Ã¼ber Groq (`llama3-8b-8192`).
4. Wandelt Antworttext mit gTTS in MP3-Audio um.
5. Gibt sowohl Antworttext als auch abspielbares Audio in einer Gradio-WeboberflÃ¤che zurÃ¼ck.

### Konversations-Pipeline

| Stufe | Komponente | Ausgabe |
|---|---|---|
| ğŸ™ï¸ Eingabe | Gradio Audio (Mikrofon/Datei) | Audio-Pfad |
| ğŸ“ Transkription | Whisper `base` | Nutzertext |
| ğŸ§  Verarbeitung | Groq + `llama3-8b-8192` | Assistententext |
| ğŸ”Š Synthese | gTTS | MP3-Antwort |
| ğŸ–¥ï¸ Bereitstellung | Gradio UI | Text + abspielbares Audio |

## â­ Funktionen

- **Speech-to-Text**: Wandelt gesprochene Sprache mit dem Whisper-Modell von OpenAI in Text um.
- **KI-generierte Antworten**: Nutzt LLaMA 8B Ã¼ber die Groq API, um auf Basis transkribierten Texts intelligente Antworten zu erzeugen.
- **Text-to-Speech**: Wandelt Antworttext mit Google Text-to-Speech (gTTS) zurÃ¼ck in Sprache um.
- **Echtzeit-Interaktion**: Interaktion Ã¼ber Mikrofon oder Upload von Audiodateien direkt Ã¼ber die WeboberflÃ¤che.
- **Einfacher Single-File-Betrieb**: Die vollstÃ¤ndige Chatbot-Pipeline ist in `voice_to_voice_chatbot.py` implementiert.
- **Mehrsprachige Dokumentation**: In der Haupt-README verweisen Links auf Sprachversionen in `i18n/`.

## ğŸ“ Projektstruktur

```text
Voice-to-text-and-voice-chatbot/
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ voice_to_voice_chatbot.py     # Main script to run the chatbot
â”œâ”€â”€ i18n/                        # Localized READMEs
â”‚   â”œâ”€â”€ README.ar.md
â”‚   â”œâ”€â”€ README.de.md
â”‚   â”œâ”€â”€ README.es.md
â”‚   â”œâ”€â”€ README.fr.md
â”‚   â”œâ”€â”€ README.ja.md
â”‚   â”œâ”€â”€ README.ko.md
â”‚   â”œâ”€â”€ README.ru.md
â”‚   â”œâ”€â”€ README.vi.md
â”‚   â”œâ”€â”€ README.zh-Hans.md
â”‚   â””â”€â”€ README.zh-Hant.md
â””â”€â”€ .auto-readme-work/
    â”œâ”€â”€ 20260228_230442/
    â””â”€â”€ 20260301_064403/
```

## âœ… Voraussetzungen

Bevor Sie beginnen, stellen Sie sicher, dass Sie die folgenden Anforderungen erfÃ¼llt haben:

- Python 3.7 oder hÃ¶her auf Ihrem lokalen Rechner oder Google Colab installiert.
- Ein Groq API-SchlÃ¼ssel. Sie kÃ¶nnen sich fÃ¼r einen API-SchlÃ¼ssel bei [Groq](https://groq.com/) anmelden.
- [Google Colab](https://colab.research.google.com/) oder eine lokale Python-Umgebung mit den erforderlichen Bibliotheken.
- Internetzugang fÃ¼r:
  - initialer Download des Whisper-Modells.
  - Groq API-Aufrufe.
  - gTTS Audioerzeugung.

### Anforderungen auf einen Blick

| Anforderung | Warum es nÃ¶tig ist |
|---|---|
| Python `3.7+` | Laufzeit fÃ¼r das Chatbot-Skript und AbhÃ¤ngigkeiten |
| Groq API Key | Authentifizierter Zugriff auf LLaMA-Modell-Inferenz |
| Colab oder lokale Umgebung | AusfÃ¼hrungsumgebung fÃ¼r Gradio + ML-Bibliotheken |
| Internetzugang | Whisper-Modell-Download, Groq-Anfragen, gTTS-Synthese |

## ğŸ› ï¸ Installation

FÃ¼hren Sie diese Schritte aus, um das Projekt einzurichten:

1. **Repository klonen**

```bash
git clone https://github.com/aquibali01/voice-to-voice-chatbot.git
cd voice-to-voice-chatbot
```

2. **AbhÃ¤ngigkeiten installieren**

Installieren Sie die benÃ¶tigten Python-Bibliotheken:

```bash
pip install -r requirements.txt
```

Alternativ in Google Colab:

```python
!pip install gradio groq-api openai-whisper gtts
```

## âš™ï¸ Konfiguration

### Groq API-SchlÃ¼ssel einrichten

Exportieren Sie Ihren Groq API-SchlÃ¼ssel:

```bash
export GROQ_API_KEY='your_groq_api_key'
```

In Google Colab setzen Sie ihn in der Laufzeit:

```python
import os
os.environ['GROQ_API_KEY'] = 'your_groq_api_key'
```

### Wichtiger Laufzeit-Hinweis (aktuelles Code-Verhalten)

Das aktuelle Skript initialisiert den Groq-Client mit einem hartkodierten Platzhalter:

```python
client = Groq(api_key="your_groq_api_key")
```

Wenn Sie `GROQ_API_KEY` nur in der Umgebung gesetzt haben, aktualisieren Sie das Skript, damit es aus `os.environ` liest (oder ersetzen Sie den Platzhalter direkt), andernfalls kÃ¶nnen Authentifizierungsaufrufe fehlschlagen.

## â–¶ï¸ Verwendung

Starten Sie den Chatbot mit:

```bash
python voice_to_voice_chatbot.py
```

Oder in Google Colab:

Kopieren Sie das Skript in eine Code-Zelle und fÃ¼hren Sie es aus.

Die Gradio-OberflÃ¤che startet lokal und ermÃ¶glicht die Interaktion mit dem Chatbot.

### Interaktion mit dem Chatbot

- **Mikrofon verwenden**: Sprechen Sie direkt in das Mikrofon. Der Chatbot transkribiert Ihre Sprache, erzeugt eine Antwort und spielt sie als Audio ab.
- **Audio hochladen**: Laden Sie eine voraufgezeichnete Audiodatei hoch. Der Chatbot transkribiert die Aufnahme, erzeugt eine Antwort und spielt das synthetisierte Audio ab.

## ğŸ¬ Beispiele

### Beispielhafter Sprachablauf

1. Aufnahme: "What are three tips to learn Python quickly?"
2. Whisper transkribiert Ihren Eingabetext.
3. Das Groq-LLaMA-Modell erzeugt eine Antwort.
4. gTTS erstellt eine MP3-Antwort.
5. Gradio zeigt Antworttext und einen Audio-Player an.

### Beispielhafter AusfÃ¼hrungsbefehl

```bash
python voice_to_voice_chatbot.py
```

Erwartetes Ergebnis: Eine lokale Gradio-App Ã¶ffnet sich in Ihrem Browser mit einem Audioeingang und zwei Ausgaben (Text + Audio).

## ğŸ§ª Entwicklungshinweise

- Haupt-Pipeline-Funktion: `chatbot_pipeline(audio_path)`.
- Das Whisper-Modell wird beim Start mit `whisper.load_model("base")` geladen.
- TemporÃ¤re MP3-Dateien werden mit `NamedTemporaryFile(..., delete=False)` erstellt.
- Fehlerbehandlung gibt aktuell `(str(e), None)` an die UI zurÃ¼ck.
- `requirements.txt` enthÃ¤lt sowohl `whisper` als auch `openai-whisper`; je nach Umgebung kann das redundant sein.

## ğŸ Fehlerbehebung

### HÃ¤ufige Probleme

`ModuleNotFoundError`: Stellen Sie sicher, dass das richtige Whisper-Paket installiert ist:

```python
!pip install -U openai-whisper
```

`Groq API Key Error`: ÃœberprÃ¼fen Sie die VerfÃ¼gbarkeit und GÃ¼ltigkeit Ihres SchlÃ¼ssels in Umgebung oder Skript.

ZusÃ¤tzliche Fehlerbehebung:

- Wenn die App mit Authentifizierungsfehlern endet, prÃ¼fen Sie den hartkodierten Wert `api_key="your_groq_api_key"` in `voice_to_voice_chatbot.py`.
- Wenn keine Mikrofonaufnahme verfÃ¼gbar ist, laden Sie zuerst eine Audiodatei hoch, um die STT â†’ LLM â†’ TTS-Pipeline zu validieren.
- Wenn das Antwort-Audio leer ist, prÃ¼fen Sie den ausgehenden Netzwerkzugriff fÃ¼r gTTS und Groq.

### Schnelle Diagnose-Checkliste

| PrÃ¼fung | Validierung |
|---|---|
| API-Key-Konfiguration | `Groq(api_key=...)` bleibt nicht als Platzhalter stehen |
| Whisper-Installation | `openai-whisper` lÃ¤sst sich sauber importieren |
| Netzwerkpfad | Ausgehender Zugriff fÃ¼r Groq + gTTS verfÃ¼gbar |
| Audioquelle | Mikrofonberechtigungen aktiviert oder Dateiupload funktioniert |

## ğŸ—ºï¸ Roadmap

- Groq API-SchlÃ¼ssel standardmÃ¤ÃŸig direkt aus Umgebungsvariablen lesen.
- Tests fÃ¼r Pipeline-Hilfsfunktionen hinzufÃ¼gen.
- Optionale Modell- und Konfigurationseinstellungen Ã¼ber Umgebungsvariablen oder CLI-Argumente hinzufÃ¼gen.
- Bereitstellungsoptionen hinzufÃ¼gen (zum Beispiel Docker oder Hugging Face Spaces).

## â¤ï¸ Support

| Donate | PayPal | Stripe |
|---|---|---|
| [![Donate](https://img.shields.io/badge/Donate-LazyingArt-0EA5E9?style=for-the-badge&logo=ko-fi&logoColor=white)](https://chat.lazying.art/donate) | [![PayPal](https://img.shields.io/badge/PayPal-RongzhouChen-00457C?style=for-the-badge&logo=paypal&logoColor=white)](https://paypal.me/RongzhouChen) | [![Stripe](https://img.shields.io/badge/Stripe-Donate-635BFF?style=for-the-badge&logo=stripe&logoColor=white)](https://buy.stripe.com/aFadR8gIaflgfQV6T4fw400) |

## ğŸ¤ Mitwirken

BeitrÃ¤ge sind willkommen. Bitte forken Sie dieses Repository, erstellen Sie einen neuen Branch und senden Sie einen Pull Request mit Ihren Ã„nderungen.

Vorgeschlagener Beitragsablauf:

1. Repository forken und klonen.
2. Einen Feature-Branch erstellen.
3. Ã„nderungen implementieren und testen.
4. Einen Pull Request mit klarer Beschreibung und BegrÃ¼ndung Ã¶ffnen.

## ğŸ“„ Lizenz

Dieses Projekt ist derzeit als MIT-lizenziert dokumentiert. Siehe die LICENSE-Datei fÃ¼r Details.

Annahme: Eine `LICENSE`-Datei ist vorgesehen, kÃ¶nnte im aktuellen Repository-Snapshot jedoch noch nicht vorhanden sein.
