[English](../README.md) ¬∑ [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](README.ar.md) ¬∑ [Espa√±ol](README.es.md) ¬∑ [Fran√ßais](README.fr.md) ¬∑ [Êó•Êú¨Ë™û](README.ja.md) ¬∑ [ÌïúÍµ≠Ïñ¥](README.ko.md) ¬∑ [Ti·∫øng Vi·ªát](README.vi.md) ¬∑ [‰∏≠Êñá (ÁÆÄ‰Ωì)](README.zh-Hans.md) ¬∑ [‰∏≠ÊñáÔºàÁπÅÈ´îÔºâ](README.zh-Hant.md) ¬∑ [Deutsch](README.de.md) ¬∑ [–†—É—Å—Å–∫–∏–π](README.ru.md)


# Chatbot de voz a voz con Whisper, LLaMA y la API de Groq

![Python](https://img.shields.io/badge/Python-3.7%2B-3776AB?logo=python&logoColor=white)
![Whisper](https://img.shields.io/badge/STT-OpenAI%20Whisper-1f6feb)
![Groq](https://img.shields.io/badge/LLM-Groq%20LLaMA%203--8B-FF6B35)
![gTTS](https://img.shields.io/badge/TTS-Google%20gTTS-34A853)
![UI](https://img.shields.io/badge/UI-Gradio-F97316)
![Status](https://img.shields.io/badge/Project-Active%20Prototype-2ea44f)

Este proyecto es un chatbot de voz a voz en tiempo real que aprovecha Whisper de OpenAI para la transcripci√≥n de voz a texto, LLaMA 8B mediante la API de Groq para generar respuestas, y Google Text-to-Speech (gTTS) para convertir texto nuevamente en voz. La interfaz del chatbot est√° construida con Gradio, lo que permite a los usuarios interactuar con el bot hablando o subiendo archivos de audio.

## Resumen

La app implementa un ciclo completo de conversaci√≥n por audio en un solo script de Python:

1. Acepta audio del usuario desde micr√≥fono o archivo subido.
2. Transcribe voz a texto con Whisper (modelo `base`).
3. Genera una respuesta mediante Groq (`llama3-8b-8192`).
4. Convierte el texto de la respuesta de vuelta a audio MP3 usando gTTS.
5. Devuelve tanto el texto de respuesta como el audio reproducible en una interfaz web de Gradio.

### Flujo de Conversaci√≥n

| Etapa | Componente | Salida |
|---|---|---|
| üéôÔ∏è Entrada | Gradio Audio (mic/file) | Ruta de audio |
| üìù Transcripci√≥n | Whisper `base` | Texto del usuario |
| üß† Razonamiento | Groq + `llama3-8b-8192` | Texto del asistente |
| üîä S√≠ntesis | gTTS | Respuesta MP3 |
| üñ•Ô∏è Entrega | Interfaz de Gradio | Texto + audio reproducible |

## Caracter√≠sticas

- **Voz a texto**: Convierte lenguaje hablado en texto usando el modelo Whisper de OpenAI.
- **Respuestas generadas por IA**: Usa LLaMA 8B mediante la API de Groq para generar respuestas inteligentes basadas en el texto transcrito.
- **Texto a voz**: Convierte las respuestas de texto generadas nuevamente en voz usando Google Text-to-Speech (gTTS).
- **Interacci√≥n en tiempo real**: El chatbot funciona en tiempo real, permitiendo a los usuarios interactuar mediante micr√≥fono o subiendo archivos de audio a trav√©s de una interfaz web.
- **Ejecuci√≥n simple en un solo archivo**: Toda la canalizaci√≥n del chatbot est√° implementada en `voice_to_voice_chatbot.py` para facilitar la experimentaci√≥n.

## Estructura del Proyecto

```text
Voice-to-text-and-voice-chatbot/
‚îú‚îÄ‚îÄ voice_to_voice_chatbot.py               # Script principal para ejecutar el chatbot
‚îú‚îÄ‚îÄ requirements.txt                        # Lista de dependencias de Python
‚îú‚îÄ‚îÄ README.md                               # Documentaci√≥n del proyecto (ingl√©s)
‚îú‚îÄ‚îÄ i18n/                                   # READMEs localizados (planificados/generados en pipeline)
‚îî‚îÄ‚îÄ .auto-readme-work/20260228_230442/      # Contexto/artefactos de automatizaci√≥n del README
```

Referencia de estructura heredada del README can√≥nico:

```text
voice-to-voice-chatbot/
‚îú‚îÄ‚îÄ voice_to_voice_chatbot.py  # Script principal para ejecutar el chatbot
‚îú‚îÄ‚îÄ requirements.txt           # Lista de dependencias de Python
‚îú‚îÄ‚îÄ README.md                  # Documentaci√≥n del proyecto
‚îî‚îÄ‚îÄ .gitignore                 # Archivo de exclusiones de Git
```

## Requisitos Previos

Antes de comenzar, aseg√∫rate de cumplir con los siguientes requisitos:

- Python 3.7 o superior instalado en tu m√°quina local o en Google Colab.
- Una clave de API de Groq. Puedes registrarte para obtener una [aqu√≠](https://groq.com/).
- [Google Colab](https://colab.research.google.com/) o un entorno local de Python con las librer√≠as necesarias instaladas.
- Acceso a internet para:
  - Descarga inicial del modelo Whisper.
  - Llamadas a la API de Groq.
  - Generaci√≥n de audio con gTTS.

### Requisitos de un Vistazo

| Requisito | Por qu√© es necesario |
|---|---|
| Python `3.7+` | Entorno de ejecuci√≥n para el script del chatbot y sus dependencias |
| Groq API Key | Acceso autenticado a la inferencia del modelo LLaMA |
| Colab or Local Env | Entorno de ejecuci√≥n para Gradio + librer√≠as de ML |
| Internet Access | Descarga del modelo Whisper, solicitudes a Groq, s√≠ntesis con gTTS |

## Instalaci√≥n

Sigue estos pasos para configurar el proyecto:

1. **Clona el repositorio:**

```bash
git clone https://github.com/aquibali01/voice-to-voice-chatbot.git
cd voice-to-voice-chatbot
```

2. **Instala las dependencias:**

Instala las librer√≠as de Python requeridas:

```bash
pip install -r requirements.txt
```

Como alternativa, si est√°s usando Google Colab, puedes instalar las librer√≠as con:

```python
!pip install gradio groq-api openai-whisper gtts
```

## Configuraci√≥n

### Configurar Groq API Key

Agrega tu clave de API de Groq a las variables de entorno:

```bash
export GROQ_API_KEY='your_groq_api_key'
```

En Google Colab, puedes establecer la API key usando:

```python
import os
os.environ['GROQ_API_KEY'] = 'your_groq_api_key'
```

### Nota Importante de Ejecuci√≥n (Comportamiento actual del c√≥digo)

El script actual inicializa el cliente de Groq con un marcador de posici√≥n codificado:

```python
client = Groq(api_key="your_groq_api_key")
```

Si solo configuras `GROQ_API_KEY` en el entorno, actualiza el script para leer desde `os.environ` o reemplaza directamente el marcador de posici√≥n; de lo contrario, fallar√° la autenticaci√≥n con la API.

## Uso

Para iniciar el chatbot, ejecuta el script principal:

```bash
python voice_to_voice_chatbot.py
```

O en Google Colab:

Copia el script en una celda de c√≥digo y ejec√∫talo.

La interfaz de Gradio se iniciar√°, permiti√©ndote interactuar con el chatbot.

### Interactuar con el Chatbot

- **Usando micr√≥fono**: Habla directamente al micr√≥fono. El chatbot transcribir√° tu voz, generar√° una respuesta y la reproducir√° como audio.
- **Subiendo audio**: Sube un archivo de audio pregrabado. El chatbot transcribir√° el audio, generar√° una respuesta y volver√° a convertirla en voz.

## Ejemplos

### Ejemplo de Flujo de Voz

1. Graba: "What are three tips to learn Python quickly?"
2. Whisper transcribe el texto de tu prompt.
3. El modelo LLaMA de Groq genera una respuesta.
4. gTTS produce una respuesta en MP3.
5. Gradio muestra el texto de respuesta y la reproducci√≥n de audio.

### Ejemplo de Comando de Ejecuci√≥n

```bash
python voice_to_voice_chatbot.py
```

Resultado esperado: una app local de Gradio se abre en tu navegador con una entrada de audio y dos salidas (texto + audio).

## Notas de Desarrollo

- Funci√≥n principal de la canalizaci√≥n: `chatbot_pipeline(audio_path)`.
- El modelo Whisper se carga al inicio: `whisper.load_model("base")`.
- Los archivos MP3 temporales se crean mediante `NamedTemporaryFile(..., delete=False)`.
- El manejo de errores actualmente devuelve `(str(e), None)` a la interfaz.
- Las dependencias en `requirements.txt` incluyen tanto `whisper` como `openai-whisper`; esto puede ser redundante seg√∫n el entorno.

## Soluci√≥n de Problemas

### Problemas Comunes

`ModuleNotFoundError`: Aseg√∫rate de haber instalado la versi√≥n correcta del m√≥dulo Whisper con

```python
!pip install -U openai-whisper
```

`Groq API Key Error`: Verifica de nuevo tu API key y aseg√∫rate de que est√© configurada correctamente en las variables de entorno.

Soluci√≥n de problemas adicional:

- Si la app falla de inmediato con errores de autenticaci√≥n, verifica el `api_key="your_groq_api_key"` codificado en `voice_to_voice_chatbot.py`.
- Si la captura por micr√≥fono no est√° disponible, sube primero un archivo de audio para validar la canalizaci√≥n STT -> LLM -> TTS.
- Si el audio de respuesta est√° vac√≠o, confirma el acceso de red saliente para gTTS.

### Lista R√°pida de Diagn√≥stico

| Verificaci√≥n | Validaci√≥n |
|---|---|
| API key wiring | `Groq(api_key=...)` no se deja como marcador de posici√≥n |
| Whisper install | `openai-whisper` se importa correctamente |
| Network path | Hay acceso saliente disponible para Groq + gTTS |
| Audio source | Permisos de micr√≥fono habilitados o carga de archivo funcional |

## Hoja de Ruta

- Leer Groq API key directamente desde variables de entorno de forma predeterminada.
- A√±adir tests para funciones auxiliares de la canalizaci√≥n.
- A√±adir configuraci√≥n opcional de modelo mediante variables de entorno o argumentos CLI.
- A√±adir archivos README i18n bajo `i18n/` que coincidan con los enlaces de navegaci√≥n por idioma.
- A√±adir opciones de despliegue (por ejemplo, Docker o Hugging Face Spaces).

## Contribuciones

Las contribuciones son bienvenidas. Haz un fork de este repositorio, crea una rama nueva y env√≠a un pull request con tus cambios.

Flujo de contribuci√≥n sugerido:

1. Haz fork y clona el repositorio.
2. Crea una rama de funcionalidad.
3. Realiza y prueba tus cambios.
4. Abre un pull request con una descripci√≥n clara.

## Soporte

No se encontraron enlaces expl√≠citos de donaci√≥n/patrocinio en el contenido actual del repositorio. Si los mantenedores a√±aden canales de soporte, deber√≠an listarse aqu√≠.

## Licencia

Este proyecto est√° licenciado bajo la licencia MIT. Consulta el archivo LICENSE para m√°s detalles.

Suposici√≥n: se espera un archivo `LICENSE`, pero puede que a√∫n no est√© presente en esta instant√°nea del repositorio.
