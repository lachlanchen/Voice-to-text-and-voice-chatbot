[English](../README.md) Â· [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README.ar.md) Â· [EspaÃ±ol](README.es.md) Â· [FranÃ§ais](README.fr.md) Â· [æ—¥æœ¬èª](README.ja.md) Â· [í•œêµ­ì–´](README.ko.md) Â· [Tiáº¿ng Viá»‡t](README.vi.md) Â· [ä¸­æ–‡ (ç®€ä½“)](README.zh-Hans.md) Â· [ä¸­æ–‡ï¼ˆç¹é«”ï¼‰](README.zh-Hant.md) Â· [Deutsch](README.de.md) Â· [Ğ ÑƒÑÑĞºĞ¸Ğ¹](README.ru.md)


[![LazyingArt banner](https://github.com/lachlanchen/lachlanchen/raw/main/figs/banner.png)](https://github.com/lachlanchen/lachlanchen/blob/main/figs/banner.png)

# Chatbot de voz a voz con Whisper, LLaMA y la API de Groq

![Python](https://img.shields.io/badge/Python-3.7%2B-3776AB?logo=python&logoColor=white)
![Whisper](https://img.shields.io/badge/STT-OpenAI%20Whisper-1f6feb)
![Groq](https://img.shields.io/badge/LLM-Groq%20LLaMA%203--8B-FF6B35)
![gTTS](https://img.shields.io/badge/TTS-Google%20gTTS-34A853)
![UI](https://img.shields.io/badge/UI-Gradio-F97316)
![Status](https://img.shields.io/badge/Project-Active%20Prototype-2ea44f)

Este proyecto es un chatbot de voz a voz en tiempo real que utiliza Whisper de OpenAI para la transcripciÃ³n de voz a texto, LLaMA 3 8B mediante la API de Groq para generar respuestas y Google Text-to-Speech (gTTS) para convertir texto de nuevo en voz. La interfaz usa Gradio para que los usuarios interactÃºen hablando o subiendo archivos de audio.

## Overview

La aplicaciÃ³n implementa un bucle completo de conversaciÃ³n por audio en un Ãºnico script de Python:

1. Acepta audio del usuario desde un micrÃ³fono o un archivo subido.
2. Transcribe el habla a texto con el modelo Whisper (`base`).
3. Genera una respuesta mediante Groq (`llama3-8b-8192`).
4. Convierte el texto de la respuesta a MP3 con gTTS.
5. Devuelve tanto el texto de respuesta como el audio reproducible en una interfaz web de Gradio.

### Conversation Pipeline

| Etapa | Componente | Salida |
|---|---|---|
| ğŸ™ï¸ Entrada | Gradio Audio (mic/file) | Ruta de audio |
| ğŸ“ TranscripciÃ³n | Whisper `base` | Texto del usuario |
| ğŸ§  Razonamiento | Groq + `llama3-8b-8192` | Texto del asistente |
| ğŸ”Š SÃ­ntesis | gTTS | Respuesta MP3 |
| ğŸ–¥ï¸ Entrega | Gradio UI | Texto + audio reproducible |

## â­ Features

- **Speech-to-Text**: Convierte lenguaje hablado a texto usando el modelo Whisper de OpenAI.
- **Respuestas generadas por IA**: Usa LLaMA 8B vÃ­a la API de Groq para generar respuestas inteligentes basadas en el texto transcrito.
- **Text-to-Speech**: Convierte el texto de respuesta a voz con Google Text-to-Speech (gTTS).
- **InteracciÃ³n en tiempo real**: InteractÃºa mediante micrÃ³fono o subiendo archivos de audio desde la interfaz web.
- **Runtime simple de un solo archivo**: El pipeline completo del chatbot estÃ¡ implementado en `voice_to_voice_chatbot.py`.
- **DocumentaciÃ³n multilingÃ¼e**: El README principal enlaza versiones traducidas en `i18n/`.

## ğŸ“ Project Structure

```text
Voice-to-text-and-voice-chatbot/
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ voice_to_voice_chatbot.py     # Main script to run the chatbot
â”œâ”€â”€ i18n/                        # Localized READMEs
â”‚   â”œâ”€â”€ README.ar.md
â”‚   â”œâ”€â”€ README.de.md
â”‚   â”œâ”€â”€ README.es.md
â”‚   â”œâ”€â”€ README.fr.md
â”‚   â”œâ”€â”€ README.ja.md
â”‚   â”œâ”€â”€ README.ko.md
â”‚   â”œâ”€â”€ README.ru.md
â”‚   â”œâ”€â”€ README.vi.md
â”‚   â”œâ”€â”€ README.zh-Hans.md
â”‚   â””â”€â”€ README.zh-Hant.md
â””â”€â”€ .auto-readme-work/
    â”œâ”€â”€ 20260228_230442/
    â””â”€â”€ 20260301_064403/
```

## âœ… Prerequisites

Antes de empezar, asegÃºrate de cumplir con estos requisitos:

- Python 3.7 o superior instalado en tu mÃ¡quina local o en Google Colab.
- Una clave de API de Groq. Puedes obtenerla en [Groq](https://groq.com/).
- [Google Colab](https://colab.research.google.com/) o un entorno Python local con las librerÃ­as necesarias.
- Acceso a Internet para:
  - Descarga inicial del modelo Whisper.
  - Llamadas a la API de Groq.
  - GeneraciÃ³n de audio con gTTS.

### Requirements at a Glance

| Requisito | Â¿Por quÃ© se necesita? |
|---|---|
| Python `3.7+` | Entorno de ejecuciÃ³n para el script del chatbot y sus dependencias |
| Groq API Key | Acceso autenticado a la inferencia del modelo LLaMA |
| Colab o entorno local | Entorno de ejecuciÃ³n para Gradio + librerÃ­as de ML |
| Acceso a Internet | Descarga del modelo Whisper, solicitudes a Groq y sÃ­ntesis con gTTS |

## ğŸ› ï¸ Installation

Sigue estos pasos para configurar el proyecto:

1. **Clona el repositorio**

```bash
git clone https://github.com/aquibali01/voice-to-voice-chatbot.git
cd voice-to-voice-chatbot
```

2. **Instala dependencias**

Instala las librerÃ­as necesarias:

```bash
pip install -r requirements.txt
```

Como alternativa, en Google Colab:

```python
!pip install gradio groq-api openai-whisper gtts
```

## âš™ï¸ Configuration

### Configura la clave de Groq

Exporta tu clave de API de Groq:

```bash
export GROQ_API_KEY='your_groq_api_key'
```

En Google Colab, configÃºrala en tiempo de ejecuciÃ³n:

```python
import os
os.environ['GROQ_API_KEY'] = 'your_groq_api_key'
```

### Nota importante de ejecuciÃ³n (comportamiento actual del cÃ³digo)

El script actual inicializa el cliente de Groq con un marcador de posiciÃ³n fijo:

```python
client = Groq(api_key="your_groq_api_key")
```

Si solo estableces `GROQ_API_KEY` en el entorno, actualiza el script para que lea `os.environ` (o reemplaza el marcador de posiciÃ³n directamente), de lo contrario las llamadas de autenticaciÃ³n pueden fallar.

## â–¶ï¸ Usage

Para iniciar el chatbot, ejecuta:

```bash
python voice_to_voice_chatbot.py
```

O en Google Colab:

Copia el script en una celda de cÃ³digo y ejecÃºtalo.

La interfaz de Gradio se abrirÃ¡ localmente para que puedas interactuar con el chatbot.

### Interacting with the Chatbot

- **Usar micrÃ³fono**: Habla directamente en el micrÃ³fono. El chatbot transcribe tu voz, genera una respuesta y la reproduce como audio.
- **Subir audio**: Sube un archivo de audio pregrabado. El chatbot transcribe la grabaciÃ³n, genera una respuesta y reproduce el audio sintetizado.

## ğŸ¬ Examples

### Example Voice Flow

1. Graba: "What are three tips to learn Python quickly?"
2. Whisper transcribe tu prompt.
3. Groq LLaMA genera una respuesta.
4. gTTS produce una respuesta MP3.
5. Gradio muestra el texto de respuesta y un reproductor de audio.

### Example Run Command

```bash
python voice_to_voice_chatbot.py
```

Resultado esperado: se abrirÃ¡ una app local de Gradio en tu navegador con una entrada de audio y dos salidas (texto + audio).

## ğŸ§ª Development Notes

- FunciÃ³n principal del pipeline: `chatbot_pipeline(audio_path)`.
- El modelo Whisper se carga al inicio con `whisper.load_model("base")`.
- Los archivos MP3 temporales se crean con `NamedTemporaryFile(..., delete=False)`.
- El manejo de errores actualmente devuelve `(str(e), None)` a la UI.
- `requirements.txt` incluye `whisper` y `openai-whisper`; puede ser redundante segÃºn el entorno.

## ğŸ Troubleshooting

### Common Issues

`ModuleNotFoundError`: AsegÃºrate de tener el paquete Whisper correcto instalado:

```python
!pip install -U openai-whisper
```

`Groq API Key Error`: Verifica que la clave exista y sea vÃ¡lida en tu entorno o script.

SoluciÃ³n adicional:

- Si la app falla con errores de autenticaciÃ³n, verifica el `api_key="your_groq_api_key"` fijo en `voice_to_voice_chatbot.py`.
- Si la captura de micrÃ³fono no estÃ¡ disponible, primero sube un archivo de audio para validar el pipeline STT â†’ LLM â†’ TTS.
- Si el audio de respuesta estÃ¡ vacÃ­o, confirma el acceso a red saliente para gTTS y Groq.

### Quick Diagnostics Checklist

| VerificaciÃ³n | ValidaciÃ³n |
|---|---|
| ConfiguraciÃ³n de la clave API | `Groq(api_key=...)` no queda como marcador de posiciÃ³n |
| InstalaciÃ³n de Whisper | `openai-whisper` se importa correctamente |
| Ruta de red | Hay acceso saliente disponible para Groq + gTTS |
| Fuente de audio | Permisos de micrÃ³fono habilitados o carga de archivo funcional |

## ğŸ—ºï¸ Roadmap

- Leer la clave API de Groq directamente de variables de entorno de forma predeterminada.
- AÃ±adir pruebas para funciones auxiliares del pipeline.
- AÃ±adir configuraciÃ³n opcional de modelo/configuraciÃ³n mediante variables de entorno o argumentos CLI.
- AÃ±adir opciones de despliegue (por ejemplo, Docker o Hugging Face Spaces).

## â¤ï¸ Support

| Donate | PayPal | Stripe |
|---|---|---|
| [![Donate](https://img.shields.io/badge/Donate-LazyingArt-0EA5E9?style=for-the-badge&logo=ko-fi&logoColor=white)](https://chat.lazying.art/donate) | [![PayPal](https://img.shields.io/badge/PayPal-RongzhouChen-00457C?style=for-the-badge&logo=paypal&logoColor=white)](https://paypal.me/RongzhouChen) | [![Stripe](https://img.shields.io/badge/Stripe-Donate-635BFF?style=for-the-badge&logo=stripe&logoColor=white)](https://buy.stripe.com/aFadR8gIaflgfQV6T4fw400) |

## ğŸ¤ Contributing

Las contribuciones son bienvenidas. Haz un fork de este repositorio, crea una rama nueva y envÃ­a un pull request con tus cambios.

Flujo de contribuciÃ³n sugerido:

1. Haz fork y clona el repositorio.
2. Crea una rama para tu funcionalidad.
3. Implementa y prueba tus cambios.
4. Abre un pull request con una descripciÃ³n y una justificaciÃ³n claras.

## ğŸ“„ License

Este proyecto se documenta actualmente bajo la licencia MIT. Consulta el archivo LICENSE para mÃ¡s detalles.

Se asume que debe existir un archivo `LICENSE`, aunque puede que aÃºn no estÃ© presente en esta instantÃ¡nea del repositorio.
