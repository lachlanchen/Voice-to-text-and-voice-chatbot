[English](../README.md) ¬∑ [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](README.ar.md) ¬∑ [Espa√±ol](README.es.md) ¬∑ [Fran√ßais](README.fr.md) ¬∑ [Êó•Êú¨Ë™û](README.ja.md) ¬∑ [ÌïúÍµ≠Ïñ¥](README.ko.md) ¬∑ [Ti·∫øng Vi·ªát](README.vi.md) ¬∑ [‰∏≠Êñá (ÁÆÄ‰Ωì)](README.zh-Hans.md) ¬∑ [‰∏≠ÊñáÔºàÁπÅÈ´îÔºâ](README.zh-Hant.md) ¬∑ [Deutsch](README.de.md) ¬∑ [–†—É—Å—Å–∫–∏–π](README.ru.md)


# Chatbot vocal-√†-vocal avec Whisper, LLaMA et l'API Groq

![Python](https://img.shields.io/badge/Python-3.7%2B-3776AB?logo=python&logoColor=white)
![Whisper](https://img.shields.io/badge/STT-OpenAI%20Whisper-1f6feb)
![Groq](https://img.shields.io/badge/LLM-Groq%20LLaMA%203--8B-FF6B35)
![gTTS](https://img.shields.io/badge/TTS-Google%20gTTS-34A853)
![UI](https://img.shields.io/badge/UI-Gradio-F97316)
![Status](https://img.shields.io/badge/Project-Active%20Prototype-2ea44f)

Ce projet est un chatbot vocal en temps r√©el qui exploite Whisper d'OpenAI pour la transcription parole-texte, LLaMA 8B via l'API Groq pour g√©n√©rer des r√©ponses, et Google Text-to-Speech (gTTS) pour reconvertir le texte en parole. L'interface du chatbot est construite avec Gradio, ce qui permet aux utilisateurs d'interagir avec le bot en parlant ou en t√©l√©versant des fichiers audio.

## Vue d'ensemble

L'application impl√©mente une boucle compl√®te de conversation audio dans un seul script Python :

1. Accepter l'audio utilisateur depuis un microphone ou un fichier t√©l√©vers√©.
2. Transcrire la parole en texte avec Whisper (mod√®le `base`).
3. G√©n√©rer une r√©ponse via Groq (`llama3-8b-8192`).
4. Reconvertir le texte de r√©ponse en audio MP3 avec gTTS.
5. Renvoyer √† la fois le texte de r√©ponse et un audio lisible dans une interface web Gradio.

### Pipeline de conversation

| √âtape | Composant | Sortie |
|---|---|---|
| üéôÔ∏è Entr√©e | Audio Gradio (mic/fichier) | Chemin audio |
| üìù Transcription | Whisper `base` | Texte utilisateur |
| üß† Raisonnement | Groq + `llama3-8b-8192` | Texte assistant |
| üîä Synth√®se | gTTS | R√©ponse MP3 |
| üñ•Ô∏è Restitution | Interface Gradio | Texte + audio lisible |

## Fonctionnalit√©s

- **Speech-to-Text** : Convertissez la parole en texte avec le mod√®le Whisper d'OpenAI.
- **R√©ponses g√©n√©r√©es par IA** : Utilisez LLaMA 8B via l'API Groq pour produire des r√©ponses pertinentes √† partir du texte transcrit.
- **Text-to-Speech** : Reconvertissez les r√©ponses textuelles en parole via Google Text-to-Speech (gTTS).
- **Interaction en temps r√©el** : Le chatbot fonctionne en temps r√©el, permettant d'interagir via microphone ou en t√©l√©versant des fichiers audio sur une interface web.
- **Ex√©cution simple sur un seul fichier** : Toute la cha√Æne du chatbot est impl√©ment√©e dans `voice_to_voice_chatbot.py` pour faciliter l'exp√©rimentation.

## Structure du projet

```text
Voice-to-text-and-voice-chatbot/
‚îú‚îÄ‚îÄ voice_to_voice_chatbot.py               # Script principal pour ex√©cuter le chatbot
‚îú‚îÄ‚îÄ requirements.txt                        # Liste des d√©pendances Python
‚îú‚îÄ‚îÄ README.md                               # Documentation du projet (anglais)
‚îú‚îÄ‚îÄ i18n/                                   # README localis√©s (pr√©vus/g√©n√©r√©s dans le pipeline)
‚îî‚îÄ‚îÄ .auto-readme-work/20260228_230442/      # Contexte/artefacts d'automatisation du README
```

R√©f√©rence de structure h√©rit√©e depuis le README canonique :

```text
voice-to-voice-chatbot/
‚îú‚îÄ‚îÄ voice_to_voice_chatbot.py  # Script principal pour ex√©cuter le chatbot
‚îú‚îÄ‚îÄ requirements.txt           # Liste des d√©pendances Python
‚îú‚îÄ‚îÄ README.md                  # Documentation du projet
‚îî‚îÄ‚îÄ .gitignore                 # Fichier d'exclusion Git
```

## Pr√©requis

Avant de commencer, assurez-vous d'avoir les √©l√©ments suivants :

- Python 3.7 ou sup√©rieur install√© sur votre machine locale ou sur Google Colab.
- Une cl√© API Groq. Vous pouvez en obtenir une [ici](https://groq.com/).
- [Google Colab](https://colab.research.google.com/) ou un environnement Python local avec les biblioth√®ques n√©cessaires install√©es.
- Un acc√®s Internet pour :
  - Le t√©l√©chargement initial du mod√®le Whisper.
  - Les appels API Groq.
  - La g√©n√©ration audio gTTS.

### Exigences en un coup d'oeil

| Exigence | Pourquoi c'est n√©cessaire |
|---|---|
| Python `3.7+` | Environnement d'ex√©cution pour le script du chatbot et ses d√©pendances |
| Cl√© API Groq | Acc√®s authentifi√© √† l'inf√©rence du mod√®le LLaMA |
| Colab ou environnement local | Environnement d'ex√©cution pour Gradio + biblioth√®ques ML |
| Acc√®s Internet | T√©l√©chargement du mod√®le Whisper, requ√™tes Groq, synth√®se gTTS |

## Installation

Suivez ces √©tapes pour configurer le projet :

1. **Cloner le d√©p√¥t :**

```bash
git clone https://github.com/aquibali01/voice-to-voice-chatbot.git
cd voice-to-voice-chatbot
```

2. **Installer les d√©pendances :**

Installez les biblioth√®ques Python requises :

```bash
pip install -r requirements.txt
```

Sinon, si vous utilisez Google Colab, vous pouvez installer les biblioth√®ques avec :

```python
!pip install gradio groq-api openai-whisper gtts
```

## Configuration

### Configurer la cl√© API Groq

Ajoutez votre cl√© API Groq aux variables d'environnement :

```bash
export GROQ_API_KEY='your_groq_api_key'
```

Dans Google Colab, vous pouvez d√©finir la cl√© API avec :

```python
import os
os.environ['GROQ_API_KEY'] = 'your_groq_api_key'
```

### Remarque importante d'ex√©cution (comportement actuel du code)

Le script actuel initialise le client Groq avec un placeholder cod√© en dur :

```python
client = Groq(api_key="your_groq_api_key")
```

Si vous d√©finissez uniquement `GROQ_API_KEY` dans l'environnement, mettez √† jour le script pour lire `os.environ` ou remplacez directement le placeholder, sinon l'authentification API √©chouera.

## Utilisation

Pour d√©marrer le chatbot, ex√©cutez le script principal :

```bash
python voice_to_voice_chatbot.py
```

Ou dans Google Colab :

Copiez le script dans une cellule de code et ex√©cutez-la.

L'interface Gradio se lancera et vous permettra d'interagir avec le chatbot.

### Interaction avec le chatbot

- **Avec le microphone** : Parlez directement dans le microphone. Le chatbot transcrira votre voix, g√©n√©rera une r√©ponse et la relira sous forme audio.
- **T√©l√©versement d'audio** : T√©l√©versez un fichier audio pr√©enregistr√©. Le chatbot transcrira l'audio, g√©n√©rera une r√©ponse et reconvertira la r√©ponse en parole.

## Exemples

### Exemple de flux vocal

1. Enregistrer : "What are three tips to learn Python quickly?"
2. Whisper transcrit votre texte de prompt.
3. Le mod√®le LLaMA de Groq g√©n√®re une r√©ponse.
4. gTTS produit une r√©ponse MP3.
5. Gradio affiche le texte de r√©ponse et la lecture audio.

### Exemple de commande d'ex√©cution

```bash
python voice_to_voice_chatbot.py
```

R√©sultat attendu : une application Gradio locale s'ouvre dans votre navigateur avec une entr√©e audio et deux sorties (texte + audio).

## Notes de d√©veloppement

- Fonction principale du pipeline : `chatbot_pipeline(audio_path)`.
- Le mod√®le Whisper est charg√© au d√©marrage : `whisper.load_model("base")`.
- Des fichiers MP3 temporaires sont cr√©√©s via `NamedTemporaryFile(..., delete=False)`.
- La gestion des erreurs renvoie actuellement `(str(e), None)` vers l'interface.
- Les d√©pendances dans `requirements.txt` incluent `whisper` et `openai-whisper` ; cela peut √™tre redondant selon l'environnement.

## D√©pannage

### Probl√®mes courants

`ModuleNotFoundError` : assurez-vous d'avoir install√© la bonne version du module Whisper avec

```python
!pip install -U openai-whisper
```

`Groq API Key Error` : v√©rifiez votre cl√© API et assurez-vous qu'elle est correctement d√©finie dans les variables d'environnement.

D√©pannage suppl√©mentaire :

- Si l'application √©choue imm√©diatement avec des erreurs d'authentification, v√©rifiez la valeur cod√©e en dur `api_key="your_groq_api_key"` dans `voice_to_voice_chatbot.py`.
- Si la capture micro n'est pas disponible, t√©l√©versez d'abord un fichier audio pour valider la cha√Æne STT -> LLM -> TTS.
- Si l'audio de r√©ponse est vide, confirmez que l'acc√®s r√©seau sortant est disponible pour gTTS.

### Checklist de diagnostic rapide

| V√©rification | Validation |
|---|---|
| C√¢blage de la cl√© API | `Groq(api_key=...)` n'est pas laiss√© avec le placeholder |
| Installation Whisper | `openai-whisper` s'importe correctement |
| Chemin r√©seau | Acc√®s sortant disponible pour Groq + gTTS |
| Source audio | Permissions micro activ√©es ou t√©l√©versement de fichier op√©rationnel |

## Feuille de route

- Lire la cl√© API Groq directement depuis les variables d'environnement par d√©faut.
- Ajouter des tests pour les fonctions utilitaires du pipeline.
- Ajouter des param√®tres optionnels de mod√®le/configuration via variables d'environnement ou arguments CLI.
- Ajouter des fichiers README i18n sous `i18n/` correspondant aux liens de navigation de langue.
- Ajouter des options de d√©ploiement (par exemple Docker ou Hugging Face Spaces).

## Contribution

Les contributions sont les bienvenues ! Veuillez forker ce d√©p√¥t, cr√©er une nouvelle branche et soumettre une pull request avec vos modifications.

Flux de contribution sugg√©r√© :

1. Forker et cloner le d√©p√¥t.
2. Cr√©er une branche de fonctionnalit√©.
3. Effectuer et tester vos modifications.
4. Ouvrir une pull request avec une description claire.

## Support

Aucun lien explicite de don/sponsoring n'a √©t√© trouv√© dans le contenu actuel du d√©p√¥t. Si les mainteneurs ajoutent des canaux de support, ils devraient √™tre list√©s ici.

## Licence

Ce projet est sous licence MIT. Consultez le fichier LICENSE pour plus de d√©tails.

Hypoth√®se : un fichier `LICENSE` est pr√©vu, mais peut ne pas encore √™tre pr√©sent dans cet instantan√© du d√©p√¥t.
