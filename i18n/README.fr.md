[English](../README.md) Â· [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README.ar.md) Â· [EspaÃ±ol](README.es.md) Â· [FranÃ§ais](README.fr.md) Â· [æ—¥æœ¬èª](README.ja.md) Â· [í•œêµ­ì–´](README.ko.md) Â· [Tiáº¿ng Viá»‡t](README.vi.md) Â· [ä¸­æ–‡ (ç®€ä½“)](README.zh-Hans.md) Â· [ä¸­æ–‡ï¼ˆç¹é«”ï¼‰](README.zh-Hant.md) Â· [Deutsch](README.de.md) Â· [Ğ ÑƒÑÑĞºĞ¸Ğ¹](README.ru.md)


[![LazyingArt banner](https://github.com/lachlanchen/lachlanchen/raw/main/figs/banner.png)](https://github.com/lachlanchen/lachlanchen/blob/main/figs/banner.png)

# Chatbot vocal-to-vocal avec Whisper, LLaMA et l'API Groq

![Python](https://img.shields.io/badge/Python-3.7%2B-3776AB?logo=python&logoColor=white)
![Whisper](https://img.shields.io/badge/STT-OpenAI%20Whisper-1f6feb)
![Groq](https://img.shields.io/badge/LLM-Groq%20LLaMA%203--8B-FF6B35)
![gTTS](https://img.shields.io/badge/TTS-Google%20gTTS-34A853)
![UI](https://img.shields.io/badge/UI-Gradio-F97316)
![Status](https://img.shields.io/badge/Project-Active%20Prototype-2ea44f)

Ce projet est un chatbot vocal en temps rÃ©el qui exploite Whisper d'OpenAI pour la transcription de la parole en texte, LLaMA 3 8B via l'API Groq pour gÃ©nÃ©rer les rÃ©ponses, et Google Text-to-Speech (gTTS) pour reconvertir le texte en parole. L'interface utilise Gradio afin que les utilisateurs puissent interagir en parlant ou en tÃ©lÃ©versant des fichiers audio.

## PrÃ©sentation

L'application implÃ©mente une boucle de conversation audio complÃ¨te dans un seul script Python :

1. Accepter l'audio utilisateur depuis un microphone ou un fichier uploadÃ©.
2. Transcrire la parole en texte avec le modÃ¨le Whisper (`base`).
3. GÃ©nÃ©rer une rÃ©ponse via Groq (`llama3-8b-8192`).
4. Reconvertir le texte de rÃ©ponse en MP3 via gTTS.
5. Retourner Ã  la fois le texte de rÃ©ponse et l'audio jouable dans une interface web Gradio.

### Pipeline de conversation

| Ã‰tape | Composant | Sortie |
|---|---|---|
| ğŸ™ï¸ EntrÃ©e | Gradio Audio (mic/fichier) | Chemin audio |
| ğŸ“ Transcription | Whisper `base` | Texte utilisateur |
| ğŸ§  Raisonnement | Groq + `llama3-8b-8192` | Texte de l'assistant |
| ğŸ”Š SynthÃ¨se | gTTS | RÃ©ponse MP3 |
| ğŸ–¥ï¸ Livraison | Gradio UI | Texte + audio lisible |

## â­ FonctionnalitÃ©s

- **Speech-to-Text** : Convertir le langage parlÃ© en texte avec le modÃ¨le Whisper d'OpenAI.
- **RÃ©ponses gÃ©nÃ©rÃ©es par IA** : Utiliser LLaMA 8B via l'API Groq pour gÃ©nÃ©rer des rÃ©ponses intelligentes Ã  partir du texte transcrit.
- **Text-to-Speech** : Reconvertir le texte de rÃ©ponse en parole via Google Text-to-Speech (gTTS).
- **Interaction en temps rÃ©el** : Interagir via microphone ou en tÃ©lÃ©chargeant des fichiers audio via l'interface web.
- **Runtime simple en un seul fichier** : Le pipeline complet du chatbot est implÃ©mentÃ© dans `voice_to_voice_chatbot.py`.
- **Documentation multilingue** : Le README principal est reproduit via des liens vers des traductions localisÃ©es dans `i18n/`.

## ğŸ“ Structure du projet

```text
Voice-to-text-and-voice-chatbot/
â”œâ”€â”€ README.md                     # Documentation principale du projet (anglais)
â”œâ”€â”€ requirements.txt              # DÃ©pendances Python
â”œâ”€â”€ voice_to_voice_chatbot.py     # Script principal pour exÃ©cuter le chatbot
â”œâ”€â”€ i18n/                        # README localisÃ©s
â”‚   â”œâ”€â”€ README.ar.md
â”‚   â”œâ”€â”€ README.de.md
â”‚   â”œâ”€â”€ README.es.md
â”‚   â”œâ”€â”€ README.fr.md
â”‚   â”œâ”€â”€ README.ja.md
â”‚   â”œâ”€â”€ README.ko.md
â”‚   â”œâ”€â”€ README.ru.md
â”‚   â”œâ”€â”€ README.vi.md
â”‚   â”œâ”€â”€ README.zh-Hans.md
â”‚   â””â”€â”€ README.zh-Hant.md
â””â”€â”€ .auto-readme-work/
    â”œâ”€â”€ 20260228_230442/
    â””â”€â”€ 20260301_064403/
```

## âœ… PrÃ©requis

Avant de commencer, assurez-vous d'avoir rempli les conditions suivantes :

- Python 3.7 ou supÃ©rieur installÃ© sur votre machine locale ou Google Colab.
- Une clÃ© API Groq. Vous pouvez vous inscrire pour obtenir une clÃ© API Ã  [Groq](https://groq.com/).
- [Google Colab](https://colab.research.google.com/) ou un environnement Python local avec les bibliothÃ¨ques requises.
- Un accÃ¨s Internet pour :
  - Le tÃ©lÃ©chargement initial du modÃ¨le Whisper.
  - Les appels Ã  l'API Groq.
  - La gÃ©nÃ©ration audio avec gTTS.

### Exigences en un coup d'Å“il

| Exigence | Pourquoi c'est nÃ©cessaire |
|---|---|
| Python `3.7+` | Runtime du script du chatbot et de ses dÃ©pendances |
| ClÃ© API Groq | AccÃ¨s authentifiÃ© Ã  l'infÃ©rence du modÃ¨le LLaMA |
| Colab ou environnement local | Environnement d'exÃ©cution pour Gradio + bibliothÃ¨ques ML |
| AccÃ¨s Internet | TÃ©lÃ©chargement du modÃ¨le Whisper, requÃªtes Groq, synthÃ¨se gTTS |

## ğŸ› ï¸ Installation

Suivez ces Ã©tapes pour configurer le projet :

1. **Cloner le dÃ©pÃ´t**

```bash
git clone https://github.com/aquibali01/voice-to-voice-chatbot.git
cd voice-to-voice-chatbot
```

2. **Installer les dÃ©pendances**

Installez les bibliothÃ¨ques Python requises :

```bash
pip install -r requirements.txt
```

Alternativement, dans Google Colab :

```python
!pip install gradio groq-api openai-whisper gtts
```

## âš™ï¸ Configuration

### Configurer la clÃ© API Groq

Exportez votre clÃ© API Groq :

```bash
export GROQ_API_KEY='your_groq_api_key'
```

Dans Google Colab, dÃ©finissez-la pendant l'exÃ©cution :

```python
import os
os.environ['GROQ_API_KEY'] = 'your_groq_api_key'
```

### Remarque importante sur le runtime actuel (comportement du code)

Le script actuel initialise le client Groq avec un placeholder codÃ© en dur :

```python
client = Groq(api_key="your_groq_api_key")
```

Si vous ne dÃ©finissez `GROQ_API_KEY` que dans l'environnement, mettez Ã  jour le script pour lire `os.environ` (ou remplacez directement le placeholder), sinon les appels d'authentification peuvent Ã©chouer.

## â–¶ï¸ Utilisation

Pour dÃ©marrer le chatbot, exÃ©cutez :

```bash
python voice_to_voice_chatbot.py
```

Ou dans Google Colab :

Copiez le script dans une cellule de code et exÃ©cutez-le.

L'interface Gradio se lancera localement, vous permettant d'interagir avec le chatbot.

### Interagir avec le chatbot

- **Utiliser le micro** : Parlez directement dans le microphone. Le chatbot transcrit votre voix, gÃ©nÃ¨re une rÃ©ponse et la lit en audio.
- **TÃ©lÃ©charger un audio** : TÃ©lÃ©versez un fichier audio prÃ©enregistrÃ©. Le chatbot transcrit l'enregistrement, gÃ©nÃ¨re une rÃ©ponse et joue l'audio synthÃ©tisÃ©.

## ğŸ¬ Exemples

### Exemple de flux vocal

1. Enregistrement : "What are three tips to learn Python quickly?"
2. Whisper transcrit votre texte de prompt.
3. Le modÃ¨le Groq LLaMA gÃ©nÃ¨re une rÃ©ponse.
4. gTTS produit une rÃ©ponse MP3.
5. Gradio affiche le texte de rÃ©ponse et un lecteur audio.

### Exemple de commande d'exÃ©cution

```bash
python voice_to_voice_chatbot.py
```

RÃ©sultat attendu : une app Gradio locale s'ouvre dans votre navigateur avec une entrÃ©e audio et deux sorties (texte + audio).

## ğŸ§ª Notes de dÃ©veloppement

- Fonction principale du pipeline : `chatbot_pipeline(audio_path)`.
- Le modÃ¨le Whisper est chargÃ© au dÃ©marrage avec `whisper.load_model("base")`.
- Les fichiers MP3 temporaires sont crÃ©Ã©s avec `NamedTemporaryFile(..., delete=False)`.
- La gestion des erreurs renvoie actuellement `(str(e), None)` vers l'UI.
- `requirements.txt` inclut Ã  la fois `whisper` et `openai-whisper` ; cela peut Ãªtre redondant selon l'environnement.

## ğŸ DÃ©pannage

### ProblÃ¨mes courants

`ModuleNotFoundError` : assurez-vous d'installer le bon package Whisper :

```python
!pip install -U openai-whisper
```

`Groq API Key Error` : vÃ©rifiez la disponibilitÃ© et la validitÃ© de la clÃ© dans votre environnement ou votre script.

DÃ©pannage supplÃ©mentaire :

- Si l'application Ã©choue avec des erreurs d'authentification, vÃ©rifiez la valeur codÃ©e en dur `api_key="your_groq_api_key"` dans `voice_to_voice_chatbot.py`.
- Si la capture du microphone n'est pas disponible, tÃ©lÃ©chargez d'abord un fichier audio pour valider le pipeline STT â†’ LLM â†’ TTS.
- Si l'audio de rÃ©ponse est vide, confirmez l'accÃ¨s rÃ©seau sortant pour gTTS et Groq.

### Liste de contrÃ´le de diagnostic rapide

| VÃ©rification | Validation |
|---|---|
| Branchement de la clÃ© API | `Groq(api_key=...)` n'est pas laissÃ© comme placeholder |
| Installation de Whisper | `openai-whisper` s'importe correctement |
| Chemin rÃ©seau | L'accÃ¨s sortant est disponible pour Groq + gTTS |
| Source audio | Permissions micro activÃ©es ou upload de fichier opÃ©rationnel |

## ğŸ—ºï¸ Feuille de route

- Lire la clÃ© API Groq directement depuis les variables d'environnement par dÃ©faut.
- Ajouter des tests pour les fonctions utilitaires du pipeline.
- Ajouter des paramÃ¨tres optionnels de modÃ¨le/config via variables d'environnement ou arguments CLI.
- Ajouter des options de dÃ©ploiement (par exemple, Docker ou Hugging Face Spaces).

## â¤ï¸ Support

| Donate | PayPal | Stripe |
|---|---|---|
| [![Donate](https://img.shields.io/badge/Donate-LazyingArt-0EA5E9?style=for-the-badge&logo=ko-fi&logoColor=white)](https://chat.lazying.art/donate) | [![PayPal](https://img.shields.io/badge/PayPal-RongzhouChen-00457C?style=for-the-badge&logo=paypal&logoColor=white)](https://paypal.me/RongzhouChen) | [![Stripe](https://img.shields.io/badge/Stripe-Donate-635BFF?style=for-the-badge&logo=stripe&logoColor=white)](https://buy.stripe.com/aFadR8gIaflgfQV6T4fw400) |

## ğŸ¤ Contribution

Les contributions sont les bienvenues. Forkez ce dÃ©pÃ´t, crÃ©ez une nouvelle branche, et soumettez une pull request avec vos modifications.

Flux de contribution suggÃ©rÃ© :

1. Forker et cloner le dÃ©pÃ´t.
2. CrÃ©er une branche de fonctionnalitÃ©.
3. ImplÃ©menter et tester vos modifications.
4. Ouvrir une pull request avec une description claire et une justification.

## ğŸ“„ Licence

Ce projet est actuellement documentÃ© comme Ã©tant sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.

HypothÃ¨se : un fichier `LICENSE` est prÃ©vu mais peut ne pas Ãªtre encore prÃ©sent dans cette version du dÃ©pÃ´t.
